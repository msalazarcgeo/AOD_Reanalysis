---
title: "Merge data like original"
format: html
---

##  Objective 

This notebook is build only to show how to generate a dataframe that was use to obthain the the results of the article. 


Since is has to be store in a `RDA` I will do it on *R*. Since all the data has been dawnloaded in a specific path 
```{r}
pacman::p_load(tidyverse, purrr, sf)

```

Load all the csv files downloaded from the SINAICA API


```{r}
path_crude_files <- '../data/Crude_stations/'
temp_files <- list.files(path_crude_files, 
    full.names = TRUE,
    pattern="\\.csv$")
#temp_files = paste(path_crude_files,temp_files , sep="")
#myfiles = lapply(temp_files, read.delim)
#combined_data <- map_dfr(temp_files, read_csv)

```

Open all the files and to merge into a single dataframe

```{r}
df_li = list()
counter= 1
for(file_csv in 1:length(temp_files)){
    print(temp_files[[file_csv]])
    df_temp <- read_csv(temp_files[[file_csv]])
    if(nrow(df_temp)> 0 ){
        df_li[[counter]] = df_temp
        counter = counter +1
    }
}
```

```{r}
df_data <- bind_rows(df_li)
```
Remove duplicates since some data is duplicate was reported more than once

```{r}
 df_data <- df_data %>% distinct(station_name, date, hour, parametro, .keep_all = TRUE)
```
Originaly this is done year by year here is an example that can work for the single year 
```{r}
#year_selected <- unique(year(df_data$date))

horas_num_tmp  <-  df_data%>%
    filter( parametro == 'TMP') %>%
    group_by(station_name,station_id, station_code,date)%>%
    summarize(
        horas_tmp= n(),
        TMP_mean = mean(value)
        )
    

horas_num_hr  <-  df_data%>%
    filter( parametro == 'HR') %>%
    group_by(station_name,station_id, station_code,date)%>%
    summarize(
        horas_hr = n(), 
        HR_mean = mean(value)
    )

horas_num_pm25  <-  df_data%>%
    filter( parametro == 'PM2.5') %>%
    group_by(station_name,station_id, station_code,date)%>%
    summarize(
        horas_pm25 = n(),
        PM2.5_mean = mean(value)
        )

horas_num_pm10  <-  df_data%>%
    filter( parametro == 'PM10') %>%
    group_by(station_name,station_id, station_code,date)%>%
    summarize(
        horas_pm10 = n(),
        PM10_mean = mean(value)
        )

#df_con_valid = left_join(listhoras_num_hr, horas_num_hr , by = c('fecha'='fecha'))


```


```{r}

list_df <- list(horas_num_tmp,horas_num_hr,horas_num_pm25, horas_num_pm10)
result <- reduce(list_df, inner_join,
    by = c("station_name",'station_id','station_code', "date")
)
result$station_code <- paste0(result$station_code , '_ZMVM')
```


With all the data available create the dataframe in columns for meean for the day if a new value is needed here is where the cahnges shoul be made. 

The columns needed in the file are **CVE_EST, FECHA, PM2.5_S50,         PM2.5_S60, PM2.5_S75**



```{r}
mutate(
    b = ifelse(PM2.5_mean*.5 >=12, NA, PM2.5_mean)
  )
```
```{r}

BDA_dia_sr <-result %>% mutate(
    CVE_EST = station_code,
    FECHA = date,
    PM2.5_S50  = ifelse(PM2.5_mean*.5 >=12, NA, PM2.5_mean),
    PM2.5_S60  = ifelse(PM2.5_mean*.6 >=14.2, NA, PM2.5_mean),
    PM2.5_S75  = ifelse(PM2.5_mean*.75 >=18, NA, PM2.5_mean)
)#%>%  as_tibble()%>%
 #dplyr::select(CVE_EST, FECHA, PM2.5_S50, PM2.5_S60, PM2.5_S75)
save(BDA_dia_sr, file = "../data/R_data/BDA_exemp.Rda")
head(BDA_dia_sr)
```



```{r}
#save to rda file
save(result, file = "../data/R_data/BDA_exemp.Rda")
```